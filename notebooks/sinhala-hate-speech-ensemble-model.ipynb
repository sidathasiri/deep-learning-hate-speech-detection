{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport logging\nimport sys\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom keras import regularizers\nfrom keras import metrics\nfrom keras.layers import Dense, LSTM, Conv1D, Dropout, MaxPooling1D, Flatten, Flatten, GRU, Average\nfrom keras.callbacks import ModelCheckpoint, TensorBoard\nfrom keras.layers.embeddings import Embedding\nfrom keras.models import Sequential\nfrom keras.models import load_model\nfrom keras.optimizers import Adam\nfrom keras.preprocessing import sequence\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import train_test_split\nimport emoji\nimport re\nimport glob\nlogging.basicConfig(format='%(levelname)s %(asctime)s: %(message)s', level=logging.INFO)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-13T08:15:23.988745Z","iopub.execute_input":"2022-02-13T08:15:23.989231Z","iopub.status.idle":"2022-02-13T08:15:29.075468Z","shell.execute_reply.started":"2022-02-13T08:15:23.989126Z","shell.execute_reply":"2022-02-13T08:15:29.074616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv(\"../input/sinhala-hate-speech/final.csv\")\nprint(\"Before\", data.shape)\ndata = data[pd.notnull(data['full_text_without_emoji'])]\ndata = data[pd.notnull(data['label'])]\nprint(\"After:\", data.shape)\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-13T08:15:29.076878Z","iopub.execute_input":"2022-02-13T08:15:29.077176Z","iopub.status.idle":"2022-02-13T08:15:29.321338Z","shell.execute_reply.started":"2022-02-13T08:15:29.077142Z","shell.execute_reply":"2022-02-13T08:15:29.32039Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def tokenize(text: str) -> list:\n    # text characters to split is from: https://github.com/madurangasiriwardena/corpus.sinhala.tools\n    emojis = ''.join(emj for emj in emoji.UNICODE_EMOJI.keys())\n    return [token for token in\n            re.split(r'[.…,‌ ¸‚\\\"/|—¦”‘\\'“’´!@#$%^&*+\\-£?˜()\\[\\]{\\}:;–Ê  �‪‬‏0123456789' + emojis + ']', text)\n            if token != \"\"]\ntokenize(\"අනේ හුකන්න කියපන් උන්ට\")","metadata":{"execution":{"iopub.status.busy":"2022-02-13T08:15:29.323451Z","iopub.execute_input":"2022-02-13T08:15:29.323792Z","iopub.status.idle":"2022-02-13T08:15:29.334131Z","shell.execute_reply.started":"2022-02-13T08:15:29.323756Z","shell.execute_reply":"2022-02-13T08:15:29.332925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def tokenize_corpus(corpus: list) -> list:\n    return [tokenize(text) for text in corpus]\ntokenized_corpus = tokenize_corpus([\"අනේ හුකන්න කියපන් උන්ට\", \"පාහර බැල්ලි එනෝ මෙතන මට වැඩ කියාදෙන්න හෙළුවෙන්\"])\ntokenized_corpus","metadata":{"execution":{"iopub.status.busy":"2022-02-13T08:15:29.33621Z","iopub.execute_input":"2022-02-13T08:15:29.336798Z","iopub.status.idle":"2022-02-13T08:15:29.345988Z","shell.execute_reply.started":"2022-02-13T08:15:29.336754Z","shell.execute_reply":"2022-02-13T08:15:29.344846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MAX_WORD_COUNT = 60 \nDATA_SET_CLASSES = {\n    0: [0, 1],\n    1: [1, 0]\n}","metadata":{"execution":{"iopub.status.busy":"2022-02-13T08:15:29.347537Z","iopub.execute_input":"2022-02-13T08:15:29.347934Z","iopub.status.idle":"2022-02-13T08:15:29.355548Z","shell.execute_reply.started":"2022-02-13T08:15:29.347893Z","shell.execute_reply":"2022-02-13T08:15:29.354617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def transform_class_to_one_hot_representation(classes: list):\n    return np.array([DATA_SET_CLASSES[cls] for cls in classes])\ntransform_class_to_one_hot_representation([1,0,1])","metadata":{"execution":{"iopub.status.busy":"2022-02-13T08:15:29.356855Z","iopub.execute_input":"2022-02-13T08:15:29.357311Z","iopub.status.idle":"2022-02-13T08:15:29.367515Z","shell.execute_reply.started":"2022-02-13T08:15:29.357268Z","shell.execute_reply":"2022-02-13T08:15:29.366349Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_dictionary(corpus_token: list) -> dict:\n    word_frequency = {}\n    dictionary = {}\n\n    for tweet in corpus_token:\n        for token in tweet:\n            if token in word_frequency:\n                word_frequency[token] += 1\n            else:\n                word_frequency[token] = 1\n\n    frequencies = list(word_frequency.values())\n    unique_words = list(word_frequency.keys())\n\n    # sort words by its frequency\n    frequency_indexes = np.argsort(frequencies)[::-1]  # reverse for descending\n    for index, frequency_index in enumerate(frequency_indexes):\n        # 0 is not used and 1 is for UNKNOWN\n        dictionary[unique_words[frequency_index]] = index + 2\n\n    return dictionary\nprint(tokenized_corpus)\ndictionary = build_dictionary(tokenized_corpus)\ndictionary","metadata":{"execution":{"iopub.status.busy":"2022-02-13T08:15:29.369378Z","iopub.execute_input":"2022-02-13T08:15:29.369861Z","iopub.status.idle":"2022-02-13T08:15:29.383465Z","shell.execute_reply.started":"2022-02-13T08:15:29.36982Z","shell.execute_reply":"2022-02-13T08:15:29.382234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def transform_to_dictionary_values(corpus_token: list, dictionary: dict) -> list:\n    x_corpus = []\n    for tweet in corpus_token:\n        # 1 is for unknown (not in dictionary)\n        x_corpus.append([dictionary[token] if token in dictionary else 1 for token in tweet])\n\n    return x_corpus\ntransform_to_dictionary_values(tokenized_corpus, dictionary)","metadata":{"execution":{"iopub.status.busy":"2022-02-13T08:15:29.385479Z","iopub.execute_input":"2022-02-13T08:15:29.386304Z","iopub.status.idle":"2022-02-13T08:15:29.395583Z","shell.execute_reply.started":"2022-02-13T08:15:29.386175Z","shell.execute_reply":"2022-02-13T08:15:29.394442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_set = data.values","metadata":{"execution":{"iopub.status.busy":"2022-02-13T08:15:29.399926Z","iopub.execute_input":"2022-02-13T08:15:29.400403Z","iopub.status.idle":"2022-02-13T08:15:29.413049Z","shell.execute_reply.started":"2022-02-13T08:15:29.400363Z","shell.execute_reply":"2022-02-13T08:15:29.412231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DATA_SET_TEXT = 40\nlogging.info(\"Tokenizing the corpus\")\ncorpus_token = tokenize_corpus(data_set[:, DATA_SET_TEXT])","metadata":{"execution":{"iopub.status.busy":"2022-02-13T08:15:29.414831Z","iopub.execute_input":"2022-02-13T08:15:29.415117Z","iopub.status.idle":"2022-02-13T08:15:29.475246Z","shell.execute_reply.started":"2022-02-13T08:15:29.41509Z","shell.execute_reply":"2022-02-13T08:15:29.474464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"logging.info(\"Building the dictionary\")\ndictionary = build_dictionary(corpus_token)\ndictionary_length = len(dictionary) + 2  # 0 is not used and 1 is for UNKNOWN\ndictionary_length","metadata":{"execution":{"iopub.status.busy":"2022-02-13T08:15:29.476638Z","iopub.execute_input":"2022-02-13T08:15:29.47701Z","iopub.status.idle":"2022-02-13T08:15:29.51209Z","shell.execute_reply.started":"2022-02-13T08:15:29.476969Z","shell.execute_reply":"2022-02-13T08:15:29.511161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"logging.info(\"Transforming the corpus to dictionary values\")\nx_corpus = transform_to_dictionary_values(corpus_token, dictionary)","metadata":{"execution":{"iopub.status.busy":"2022-02-13T08:15:29.513441Z","iopub.execute_input":"2022-02-13T08:15:29.513776Z","iopub.status.idle":"2022-02-13T08:15:29.694023Z","shell.execute_reply.started":"2022-02-13T08:15:29.51374Z","shell.execute_reply":"2022-02-13T08:15:29.692964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DATA_SET_CLASS = 29\ny_corpus = transform_class_to_one_hot_representation(data_set[:, DATA_SET_CLASS])\ny_corpus","metadata":{"execution":{"iopub.status.busy":"2022-02-13T08:15:29.695552Z","iopub.execute_input":"2022-02-13T08:15:29.696058Z","iopub.status.idle":"2022-02-13T08:15:29.724365Z","shell.execute_reply.started":"2022-02-13T08:15:29.696018Z","shell.execute_reply":"2022-02-13T08:15:29.723306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_corpus = sequence.pad_sequences(x_corpus, maxlen=MAX_WORD_COUNT )\nprint(len(x_corpus))","metadata":{"execution":{"iopub.status.busy":"2022-02-13T08:15:29.728078Z","iopub.execute_input":"2022-02-13T08:15:29.730132Z","iopub.status.idle":"2022-02-13T08:15:29.77755Z","shell.execute_reply.started":"2022-02-13T08:15:29.730095Z","shell.execute_reply":"2022-02-13T08:15:29.776719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ################## Deep Neural Network ###################### #\nFOLDS_COUNT = 10\nMAX_EPOCHS = 3\nVALIDATION_TEST_SIZE = 0.12\nmax_word_count = MAX_WORD_COUNT\n\nfrom keras.models import Model, Input\ninpiut_shape = (17532,)\nmodel_input = Input(shape=inpiut_shape)\n\n# splitting data for 5-fold cross validation\nk_fold = StratifiedKFold(n_splits=FOLDS_COUNT, shuffle=True, random_state=18)\n# to split, raw format (integer) is required\ny_corpus_raw = [0 if cls[1] == 1 else 1 for cls in y_corpus]","metadata":{"execution":{"iopub.status.busy":"2022-02-13T08:15:29.778766Z","iopub.execute_input":"2022-02-13T08:15:29.77911Z","iopub.status.idle":"2022-02-13T08:15:29.800144Z","shell.execute_reply.started":"2022-02-13T08:15:29.779075Z","shell.execute_reply":"2022-02-13T08:15:29.799393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_lstm_model():\n    model = Sequential()\n    model.add(Embedding(input_dim=dictionary_length, output_dim=60, input_length=max_word_count))\n    model.add(LSTM(600))\n    model.add(Dense(units=max_word_count, activation='tanh', kernel_regularizer=regularizers.l2(0.04),\n                    activity_regularizer=regularizers.l2(0.015)))\n    model.add(Dense(units=max_word_count, activation='relu', kernel_regularizer=regularizers.l2(0.01),\n                    bias_regularizer=regularizers.l2(0.01)))\n    model.add(Dense(2, activation='softmax', kernel_regularizer=regularizers.l2(0.001)))\n    adam_optimizer = Adam(lr=0.001, decay=0.0001)\n    model.compile(loss='binary_crossentropy', optimizer=adam_optimizer, metrics=[metrics.CategoricalAccuracy(), metrics.AUC(), metrics.Precision(), metrics.Recall()])\n\n    return model\n    \n    \n#     x = Embedding(input_dim=dictionary_length, output_dim=60, input_length=max_word_count)(model_input)\n#     x = LSTM(600)(x)\n#     x = Dense(units=max_word_count, activation='tanh', kernel_regularizer=regularizers.l2(0.04),\n#                     activity_regularizer=regularizers.l2(0.015))(x)\n#     x = Dense(units=max_word_count, activation='relu', kernel_regularizer=regularizers.l2(0.01),\n#                     bias_regularizer=regularizers.l2(0.01))(x)\n#     x = Dense(2, activation='softmax', kernel_regularizer=regularizers.l2(0.001))(x)\n#     return Model(model_input, x, name='lstm_model')","metadata":{"execution":{"iopub.status.busy":"2022-02-13T08:15:29.802834Z","iopub.execute_input":"2022-02-13T08:15:29.803113Z","iopub.status.idle":"2022-02-13T08:15:29.810166Z","shell.execute_reply.started":"2022-02-13T08:15:29.803086Z","shell.execute_reply":"2022-02-13T08:15:29.809359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lstm_model = get_lstm_model()","metadata":{"execution":{"iopub.status.busy":"2022-02-13T08:15:29.811534Z","iopub.execute_input":"2022-02-13T08:15:29.812086Z","iopub.status.idle":"2022-02-13T08:15:32.579019Z","shell.execute_reply.started":"2022-02-13T08:15:29.812046Z","shell.execute_reply":"2022-02-13T08:15:32.578226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_cnn_model():\n    model = Sequential()\n    model.add(Embedding(input_dim=dictionary_length, output_dim=60, input_length=max_word_count))\n    model.add(Conv1D(32, 3, padding='same', activation='relu'))\n    model.add(MaxPooling1D())\n    model.add(Flatten())\n    model.add(Dense(250, activation='relu'))\n    model.add(Dense(2, activation='sigmoid'))\n    adam_optimizer = Adam(lr=0.001, decay=0.0001)\n    model.compile(loss='binary_crossentropy', optimizer=adam_optimizer, metrics=[metrics.CategoricalAccuracy(), metrics.AUC(), metrics.Precision(), metrics.Recall()])\n    return model\n\n#     x = Embedding(input_dim=dictionary_length, output_dim=60, input_length=max_word_count)(model_input)\n#     x = Conv1D(32, 3, padding='same', activation='relu')(x)\n#     x = MaxPooling1D()(x)\n#     x = Flatten()(x)\n#     x = Dense(250, activation='relu')(x)\n#     x = Dense(2, activation='sigmoid')(x)\n#     return Model(model_input, x, name='cnn_model')","metadata":{"execution":{"iopub.status.busy":"2022-02-13T08:15:32.58023Z","iopub.execute_input":"2022-02-13T08:15:32.580639Z","iopub.status.idle":"2022-02-13T08:15:32.588016Z","shell.execute_reply.started":"2022-02-13T08:15:32.580597Z","shell.execute_reply":"2022-02-13T08:15:32.586986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cnn_model = get_cnn_model()","metadata":{"execution":{"iopub.status.busy":"2022-02-13T08:15:32.589597Z","iopub.execute_input":"2022-02-13T08:15:32.589984Z","iopub.status.idle":"2022-02-13T08:15:32.671799Z","shell.execute_reply.started":"2022-02-13T08:15:32.589947Z","shell.execute_reply":"2022-02-13T08:15:32.67102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_bi_gru_model():\n    model = Sequential()\n    model.add(Embedding(input_dim=dictionary_length, output_dim=60, input_length=max_word_count))\n    model.add(GRU(units=256, return_sequences=True))\n    model.add(MaxPooling1D())\n    model.add(Flatten())\n    model.add(Dense(250, activation='relu'))\n    model.add(Dense(2, activation='sigmoid'))\n    adam_optimizer = Adam(lr=0.001, decay=0.0001)\n    model.compile(loss='binary_crossentropy', optimizer=adam_optimizer, metrics=[metrics.CategoricalAccuracy(), metrics.AUC(), metrics.Precision(), metrics.Recall()])\n    return model\n#     x = Embedding(input_dim=dictionary_length, output_dim=60, input_length=max_word_count)(model_input)\n#     x = GRU(units=256, return_sequences=True)(x)\n#     x = MaxPooling1D()(x)\n#     x = Flatten()(x)\n#     x = Dense(250, activation='relu')(x)\n#     x = Dense(2, activation='sigmoid')(x)\n#     return Model(model_input, x, name='gru_model')","metadata":{"execution":{"iopub.status.busy":"2022-02-13T08:15:32.674724Z","iopub.execute_input":"2022-02-13T08:15:32.674967Z","iopub.status.idle":"2022-02-13T08:15:32.682314Z","shell.execute_reply.started":"2022-02-13T08:15:32.674942Z","shell.execute_reply":"2022-02-13T08:15:32.681382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gru_model = get_bi_gru_model()","metadata":{"execution":{"iopub.status.busy":"2022-02-13T08:15:32.683596Z","iopub.execute_input":"2022-02-13T08:15:32.683984Z","iopub.status.idle":"2022-02-13T08:15:32.932088Z","shell.execute_reply.started":"2022-02-13T08:15:32.683926Z","shell.execute_reply":"2022-02-13T08:15:32.931253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# x_train, x_test, y_train, y_test = train_test_split(x_corpus, y_corpus,\n#                                                           test_size=VALIDATION_TEST_SIZE, random_state=94)","metadata":{"execution":{"iopub.status.busy":"2022-02-13T08:15:32.933414Z","iopub.execute_input":"2022-02-13T08:15:32.933865Z","iopub.status.idle":"2022-02-13T08:15:32.937271Z","shell.execute_reply.started":"2022-02-13T08:15:32.933828Z","shell.execute_reply":"2022-02-13T08:15:32.936293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"NUM_EPOCHS = 3\ndef compile_and_train(model, num_epochs): \n#     adam_optimizer = Adam(lr=0.001, decay=0.0001)\n#     model.compile(loss='binary_crossentropy', optimizer=adam_optimizer, metrics=[metrics.Accuracy(), metrics.AUC(), metrics.Precision(), metrics.Recall()])\n#     filepath = 'weights/' + model.name + '.{epoch:02d}-{loss:.2f}.hdf5'\n#     print(filepath)\n#     checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=0, save_weights_only=True,\n#                                                  save_best_only=True, mode='auto', period=1)\n#     tensor_board = TensorBoard(log_dir='logs/', histogram_freq=0, batch_size=32)\n    history = model.fit(x=x_train, y=y_train, batch_size=32, \n                     epochs=num_epochs, verbose=1, validation_split=0.2)\n    print(history)\n#     weight_files = glob.glob(os.path.join(os.getcwd(), 'weights/*'))\n#     weight_file = max(weight_files, key=os.path.getctime) # most recent file\n#     return history, weight_file","metadata":{"execution":{"iopub.status.busy":"2022-02-13T08:15:32.938629Z","iopub.execute_input":"2022-02-13T08:15:32.939005Z","iopub.status.idle":"2022-02-13T08:15:32.950132Z","shell.execute_reply.started":"2022-02-13T08:15:32.938966Z","shell.execute_reply":"2022-02-13T08:15:32.949022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# compile_and_train(lstm_model, NUM_EPOCHS)","metadata":{"execution":{"iopub.status.busy":"2022-02-13T08:15:32.953338Z","iopub.execute_input":"2022-02-13T08:15:32.953655Z","iopub.status.idle":"2022-02-13T08:15:32.959456Z","shell.execute_reply.started":"2022-02-13T08:15:32.95363Z","shell.execute_reply":"2022-02-13T08:15:32.958517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# compile_and_train(cnn_model, NUM_EPOCHS)","metadata":{"execution":{"iopub.status.busy":"2022-02-13T08:15:32.960767Z","iopub.execute_input":"2022-02-13T08:15:32.961314Z","iopub.status.idle":"2022-02-13T08:15:32.968098Z","shell.execute_reply.started":"2022-02-13T08:15:32.961267Z","shell.execute_reply":"2022-02-13T08:15:32.967209Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# compile_and_train(gru_model, NUM_EPOCHS)","metadata":{"execution":{"iopub.status.busy":"2022-02-13T08:15:32.971263Z","iopub.execute_input":"2022-02-13T08:15:32.971737Z","iopub.status.idle":"2022-02-13T08:15:32.976992Z","shell.execute_reply.started":"2022-02-13T08:15:32.971711Z","shell.execute_reply":"2022-02-13T08:15:32.976242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import f1_score\n\ndef evaluate_perf(pred, actual):\n    actual_list = [i[1] for i in actual]\n    accuracy = accuracy_score(actual_list, pred)\n    precision = precision_score(actual_list, pred, average='macro')\n    recall = recall_score(actual_list, pred, average='macro')\n    f_score = f1_score(actual_list, pred, average='macro')\n    auc = roc_auc_score(actual_list, pred)\n    return { \"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f_score\": f_score, 'auc': auc}","metadata":{"execution":{"iopub.status.busy":"2022-02-13T08:15:32.981441Z","iopub.execute_input":"2022-02-13T08:15:32.98175Z","iopub.status.idle":"2022-02-13T08:15:32.988837Z","shell.execute_reply.started":"2022-02-13T08:15:32.981724Z","shell.execute_reply":"2022-02-13T08:15:32.987954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print(evaluate_accuracy(lstm_model))\n# print(evaluate_accuracy(cnn_model))\n# print(evaluate_accuracy(gru_model))","metadata":{"execution":{"iopub.status.busy":"2022-02-13T08:15:32.99067Z","iopub.execute_input":"2022-02-13T08:15:32.991347Z","iopub.status.idle":"2022-02-13T08:15:32.997322Z","shell.execute_reply.started":"2022-02-13T08:15:32.99131Z","shell.execute_reply":"2022-02-13T08:15:32.996508Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# LSTMN_WEIGHT_FILE = os.path.join(os.getcwd(), 'weights', 'sequential_4.{epoch:02d}-{loss:.2f}.hdf5')\n# CNN_WEIGHT_FILE = os.path.join(os.getcwd(), 'weights', 'sequential_5.{epoch:02d}-{loss:.2f}.hdf5')\n# GRU_WEIGHT_FILE = os.path.join(os.getcwd(), 'weights', 'sequential_6.{epoch:02d}-{loss:.2f}.hdf5')\n\n# conv_pool_cnn_model = conv_pool_cnn(model_input)\n# all_cnn_model = all_cnn(model_input)\n# nin_cnn_model = nin_cnn(model_input)\n\n# conv_pool_cnn_model.load_weights(CONV_POOL_CNN_WEIGHT_FILE)\n# all_cnn_model.load_weights(ALL_CNN_WEIGHT_FILE)\n# nin_cnn_model.load_weights(NIN_CNN_WEIGHT_FILE)\n\nmodels = [lstm_model, cnn_model, gru_model]","metadata":{"execution":{"iopub.status.busy":"2022-02-13T08:15:32.99868Z","iopub.execute_input":"2022-02-13T08:15:32.9995Z","iopub.status.idle":"2022-02-13T08:15:33.009356Z","shell.execute_reply.started":"2022-02-13T08:15:32.999452Z","shell.execute_reply":"2022-02-13T08:15:33.008482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom scipy import stats\ndef ensemble_pred(models, test_set):\n    predictions = []\n    for model in models:\n        pred = model.predict(test_set, batch_size = 32)\n        pred = list(np.argmax(pred, axis=1))\n#         print(pred)\n        predictions.append(pred)\n    predictions_np = np.array(predictions)\n    m = stats.mode(predictions_np)\n    return m.mode[0].tolist()","metadata":{"execution":{"iopub.status.busy":"2022-02-13T08:15:33.010982Z","iopub.execute_input":"2022-02-13T08:15:33.011626Z","iopub.status.idle":"2022-02-13T08:15:33.018732Z","shell.execute_reply.started":"2022-02-13T08:15:33.011561Z","shell.execute_reply":"2022-02-13T08:15:33.01786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ens_pred = ensemble_pred(models, x_test)\n# ens_pred\n# type(ens_pred)","metadata":{"execution":{"iopub.status.busy":"2022-02-13T08:15:33.020336Z","iopub.execute_input":"2022-02-13T08:15:33.020806Z","iopub.status.idle":"2022-02-13T08:15:33.026946Z","shell.execute_reply.started":"2022-02-13T08:15:33.020745Z","shell.execute_reply":"2022-02-13T08:15:33.026054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# evaluate_perf(ens_pred, y_test)","metadata":{"execution":{"iopub.status.busy":"2022-02-13T08:15:33.028091Z","iopub.execute_input":"2022-02-13T08:15:33.02866Z","iopub.status.idle":"2022-02-13T08:15:33.035156Z","shell.execute_reply.started":"2022-02-13T08:15:33.028618Z","shell.execute_reply":"2022-02-13T08:15:33.034159Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import StratifiedKFold\nimport numpy\nfrom sklearn.metrics import classification_report\n\ncvscores = []\nkfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=7)\ny_corpus_raw = [0 if cls[1] == 1 else 1 for cls in y_corpus]\n\nfor train_n_validation_indexes, test_indexes  in kfold.split(x_corpus, y_corpus_raw):\n    x_train_n_validation = x_corpus[train_n_validation_indexes]\n    y_train_n_validation = y_corpus[train_n_validation_indexes]\n    x_test = x_corpus[test_indexes]\n    y_test = y_corpus[test_indexes]\n\n    # train and validation data sets\n#     x_train, x_valid, y_train, y_valid = train_test_split(x_train_n_validation, y_train_n_validation,\n#                                                           test_size=VALIDATION_TEST_SIZE, random_state=94)\n    lstm_model = get_lstm_model()\n    cnn_model = get_cnn_model()\n    gru_model = get_bi_gru_model()\n    lstm_model.fit(x_train_n_validation, y_train_n_validation, epochs=3, batch_size=10, verbose=1)\n    cnn_model.fit(x_train_n_validation, y_train_n_validation, epochs=3, batch_size=10, verbose=1)\n    gru_model.fit(x_train_n_validation, y_train_n_validation, epochs=3, batch_size=10, verbose=1)\n#     model.fit(x_train, y_train, epochs=3, batch_size=10, verbose=1)\n        # evaluate the model\n#     scores = model.evaluate(x_test, y_test, verbose=0)\n#     print(model.metrics_names)\n#     print(scores)\n#     print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n    prediction = ensemble_pred([lstm_model, cnn_model, gru_model], x_test)\n    print(classification_report(list(np.argmax(y_test, axis=1)), prediction, labels=[0, 1]))\n    scores = evaluate_perf(prediction, y_test)\n    print(\"score: \", scores)\n    cvscores.append(scores)\n#     cvscores.append(scores[1] * 100)\n# print(\"%.2f%% (+/- %.2f%%)\" % (numpy.mean(cvscores), numpy.std(cvscores)))\n\n# evaluate_accuracy(lstm_model)\n# def evaluate_accuracy(model):\n# #     print(DATA_SET_CLASSES)\n#     pred = model.predict(x_test, batch_size = 32)\n#     pred = list(np.argmax(pred, axis=1))\n# #     print(pred)\n# #     pred = [DATA_SET_CLASSES[i][0] for i in pred]\n# #     print(pred)\n#     y_test_list = [i[1] for i in y_test]\n# #     print(y_test_list)\n#     return accuracy_score(y_test_list, pred)","metadata":{"execution":{"iopub.status.busy":"2022-02-13T08:15:33.036998Z","iopub.execute_input":"2022-02-13T08:15:33.037505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"acc = []\npre = []\nrecall = []\nfscore = []\nauc = []\nfor i in cvscores:\n    acc.append(i['accuracy'])\n    pre.append(i['precision'])\n    recall.append(i['recall'])\n    fscore.append(i['f_score'])\n    auc.append(i['auc'])\n\nprint(\"Accuracy:\", sum(acc)/len(acc))\nprint(\"Precision:\", sum(pre)/len(pre))\nprint(\"Recall:\", sum(recall)/len(recall))\nprint(\"fScore:\", sum(fscore)/len(fscore))\nprint(\"auc:\", sum(auc)/len(auc))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}